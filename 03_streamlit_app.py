# 03_streamlit_app.py
import streamlit as st
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns

# ===========================
# 1. é é¢è¨­å®š
# ===========================
st.set_page_config(page_title="Spam Email Classifier", page_icon="ğŸ“§", layout="wide")

st.title("ğŸ“§ Spam Email Classifier")
st.caption("ä¸€å€‹ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’å»ºç«‹çš„åƒåœ¾éƒµä»¶åˆ†é¡å™¨ | 2025 ML Project by Beck Lin")

# ===========================
# 2. è¼‰å…¥æ¨¡å‹èˆ‡å‘é‡å™¨
# ===========================
@st.cache_resource
def load_models():
    vectorizer = joblib.load("models/tfidf_vectorizer.pkl")

    # è‡ªå‹•åµæ¸¬æœ€ä½³æ¨¡å‹
    import glob
    model_files = [m for m in glob.glob("models/*.pkl") if "vectorizer" not in m]
    model_path = model_files[0] if model_files else None

    if model_path:
        model = joblib.load(model_path)
        st.success(f"âœ… å·²è¼‰å…¥æ¨¡å‹ï¼š{model_path.split('/')[-1]}")
        return vectorizer, model
    else:
        st.error("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼Œè«‹å…ˆåŸ·è¡Œ train_pipeline.py")
        st.stop()

vectorizer, model = load_models()

# ===========================
# 3. ä½¿ç”¨è€…è¼¸å…¥å€
# ===========================
st.subheader("ğŸ“ æ¸¬è©¦éƒµä»¶å…§å®¹")
user_input = st.text_area(
    "è«‹è¼¸å…¥éƒµä»¶å…§å®¹ï¼š",
    height=150,
    placeholder="ä¾‹å¦‚ï¼šCongratulations! You've won a $1000 gift card. Click here to claim..."
)

col1, col2 = st.columns([1, 2])

if col1.button("ğŸ” é–‹å§‹åˆ†æ"):
    if user_input.strip() == "":
        st.warning("è«‹å…ˆè¼¸å…¥éƒµä»¶å…§å®¹ã€‚")
    else:
        X_input = vectorizer.transform([user_input])
        pred = model.predict(X_input)[0]
        try:
            proba = model.predict_proba(X_input)[0][1]
        except:
            proba = None

        if pred == 1:
            col2.error("ğŸš¨ é æ¸¬çµæœï¼š**Spam (åƒåœ¾éƒµä»¶)**")
        else:
            col2.success("âœ… é æ¸¬çµæœï¼š**Not Spam (æ­£å¸¸éƒµä»¶)**")

        if proba is not None:
            col2.metric("Spam æ©Ÿç‡", f"{proba*100:.2f}%")
            st.progress(float(proba))

# ===========================
# 4. æ¨¡å‹æ•ˆèƒ½æ‘˜è¦
# ===========================
st.markdown("---")
st.subheader("ğŸ“Š æ¨¡å‹æ•ˆèƒ½æ‘˜è¦")

try:
    df_metrics = pd.read_csv("data/model_results.csv")
    st.dataframe(df_metrics.style.highlight_max(subset=["F1"], color="lightgreen"))
except FileNotFoundError:
    st.info("âš ï¸ æ‰¾ä¸åˆ° model_results.csvï¼Œè«‹å…ˆåŸ·è¡Œ train_pipeline.pyã€‚")

# ===========================
# 5. è©é›²å±•ç¤º
# ===========================
st.markdown("---")
st.subheader("â˜ï¸ Spam / Ham è©é›²")

spam_texts = [
    "free winner cash prize money offer congratulations click claim now",
    "you have won lottery gift card free coupon claim reward now"
]
ham_texts = [
    "see you at lunch tomorrow meeting scheduled at 3pm",
    "please find attached the report for this week project update"
]

spam_wc = WordCloud(width=500, height=300, background_color="white").generate(" ".join(spam_texts))
ham_wc = WordCloud(width=500, height=300, background_color="white").generate(" ".join(ham_texts))

col1, col2 = st.columns(2)
with col1:
    st.image(spam_wc.to_array(), caption="ğŸš¨ Spam å¸¸è¦‹è©")
with col2:
    st.image(ham_wc.to_array(), caption="âœ… Ham å¸¸è¦‹è©")

# ===========================
# 6. çµ±è¨ˆåœ–è¡¨
# ===========================
st.markdown("---")
st.subheader("ğŸ“ˆ Spam vs Ham çµ±è¨ˆåˆ†æ")

spam_count, ham_count = 747, 4827
fig, ax = plt.subplots(1, 2, figsize=(10, 4))

# åœ“é¤…åœ–
ax[0].pie([ham_count, spam_count], labels=["Ham", "Spam"], autopct="%1.1f%%", colors=["#4CAF50", "#F44336"])
ax[0].set_title("è³‡æ–™é›†æ¯”ä¾‹")

# æ¨¡æ“¬é•·åº¦åˆ†å¸ƒ
np.random.seed(42)
ham_lengths = np.random.normal(80, 20, 200)
spam_lengths = np.random.normal(120, 25, 200)
sns.kdeplot(ham_lengths, ax=ax[1], label="Ham")
sns.kdeplot(spam_lengths, ax=ax[1], label="Spam", color="red")
ax[1].set_title("éƒµä»¶é•·åº¦åˆ†å¸ƒ")
ax[1].set_xlabel("å­—æ•¸")
ax[1].legend()

st.pyplot(fig)

# ===========================
# 7. æ¨¡å‹èªªæ˜
# ===========================
st.markdown("---")
with st.expander("ğŸ“˜ é—œæ–¼æ­¤æ¨¡å‹"):
    st.write("""
    - æ¨¡å‹ä½¿ç”¨ **TF-IDF å‘é‡åŒ–** + **Linear SVM**
    - è³‡æ–™ä¾†æºï¼šSMS Spam Collection Dataset
    - è©•ä¼°æŒ‡æ¨™ï¼šAccuracyã€Precisionã€Recallã€F1-score
    - å¯å³æ™‚é æ¸¬éƒµä»¶å…§å®¹æ˜¯å¦ç‚ºåƒåœ¾éƒµä»¶ã€‚
    """)

st.caption("ğŸ§  Created by Beck Lin | 2025 Machine Learning Project")
